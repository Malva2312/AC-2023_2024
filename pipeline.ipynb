{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of attributes and table names\n",
    "# Example of how to fetch data from multiple tables\n",
    "# attributes = [\"t1.attribute1\", \"t2.attribute2\", \"t3.attribute3\", \"t4.attribute4\"] # Any attribute names that we want to fetch\n",
    "# table_names = [\"table1\", \"table2\", \"table3\", \"table4\"]  # The table names that we want to join\n",
    "# join_conditions = [\"t1.id = t2.id\", \"t1.id = t3.id\", \"t1.id = t4.id\"]  # The join conditions for the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to fetch data from a single table\n",
    "attributes = [\"t1.year\", \"t1.playoff\"] # Any attribute names that we want to fetch\n",
    "table_names = [\"teams\"]  # The table names that we want to join\n",
    "join_conditions = []  # The join conditions for the tables\n",
    "\n",
    "# Removing the table names from attributes\n",
    "cleaned_attributes = [attr.split('.')[1] for attr in attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the existing SQLite database\n",
    "conn = sqlite3.connect('db/database.db')\n",
    "\n",
    "# Generate the select and join clauses dynamically\n",
    "select_clause = \", \".join(attributes)\n",
    "join_clause = f\"{table_names[0]} t1\"\n",
    "for i in range(1, len(table_names)):\n",
    "    join_clause += f\" JOIN {table_names[i]} t{i+1} ON {join_conditions[i-1]}\"\n",
    "\n",
    "# Create the complete query string\n",
    "query = f\"SELECT {select_clause} FROM {join_clause}\"\n",
    "\n",
    "# Execute the query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Convert the fetched data to a pandas dataframe\n",
    "df = pd.DataFrame(rows, columns=[attribute.split('.')[1] for attribute in attributes])\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_five_years = df[df['year'] <= 5]  # Get the first five years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60, 1)\n",
      "Shape of X_test: (15, 1)\n",
      "Shape of y_train: (60,)\n",
      "Shape of y_test: (15,)\n"
     ]
    }
   ],
   "source": [
    "target = 'playoff'  # The target attribute\n",
    "seed = 42  # The random seed for the train-test split\n",
    "train_ratio = 0.8  #   80% of the data is used for training and 20% for testing (can be changed as needed)\n",
    "\n",
    "# Perform the train-test split, ensuring the random split is the same in various runs\n",
    "x = df_first_five_years.drop(columns=[target])\n",
    "y = df_first_five_years[ target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_ratio, stratify=y, random_state=seed)\n",
    "\n",
    "print(f\"Shape of X_train: {x_train.shape}\")\n",
    "print(f\"Shape of X_test: {x_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline with different models\n",
    "# The names of the models will be used to retrieve the model from the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=seed))   # We can use any classifier here to test multiple models\n",
    "                                                                # We can also use SVC or any other classifier here\n",
    "                                                                # Maybe we should use a different seed from the split seed (using: seed=42)\n",
    "])\n",
    "\n",
    "# Fit the pipeline with the training data\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use the method pipeline.named_steps['scaler'] to retrieve data from the pipeline\n",
    "scaler_model = pipeline.named_steps['scaler']      # This will return the scaler object\n",
    "classifier_model = pipeline.named_steps['classifier']  # This will return the classifier object\n",
    "# Use this to test n models and compare them later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
